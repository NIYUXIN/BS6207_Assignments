{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the label function and loss function\n",
    "def label(x1,x2):\n",
    "    return (x1*x1+x2*x2)/2\n",
    "def loss(predict,y):\n",
    "    return sum((predict-y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly select 100 tuple with 2 numbers between 0 and 1\n",
    "size=100\n",
    "node=torch.Tensor(size,2).uniform_(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate label \n",
    "y_label=label(node[:,0],node[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_model(\n",
      "  (linear1): Linear(in_features=2, out_features=10, bias=True)\n",
      "  (linear2): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (linear3): Linear(in_features=10, out_features=1, bias=True)\n",
      "  (activation): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#define nerual network\n",
    "class nn_model(nn.Module):\n",
    "    def __init__(self,n_node):\n",
    "        super(nn_model,self).__init__()\n",
    "        self.linear1=nn.Linear(n_node,10)\n",
    "        self.linear2=nn.Linear(10,10)\n",
    "        self.linear3=nn.Linear(10,1)\n",
    "        self.activation=nn.Sigmoid()\n",
    "    def forward(self,inputs):\n",
    "        y=self.linear1(inputs)\n",
    "        y=self.activation(y)\n",
    "        y=self.linear2(y)\n",
    "        y=self.activation(y)\n",
    "        y=self.linear3(y)\n",
    "        return y\n",
    "model=nn_model(2)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.1149], requires_grad=True)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1=model.linear1.weight\n",
    "b1=model.linear1.bias\n",
    "w2=model.linear2.weight\n",
    "b2=model.linear2.bias\n",
    "w3=model.linear3.weight\n",
    "b3=model.linear3.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.1149], requires_grad=True)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.requires_grad_(True)\n",
    "b1.requires_grad_(True)\n",
    "w2.requires_grad_(True)\n",
    "b2.requires_grad_(True)\n",
    "w3.requires_grad_(True)\n",
    "b3.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define data iteration methods\n",
    "def data_iter(batch_size,node, labels):\n",
    "    num_examples = len(node)\n",
    "    indices = list(range(num_examples))\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        j = torch.LongTensor(indices[i:min(i + batch_size, num_examples)])\n",
    "        yield  node.index_select(0, j),labels.index_select(0, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use batch size ==1 and generate w.grad and b.grad in each step\n",
    "epoch=1\n",
    "batch_size=1\n",
    "result=[]\n",
    "weight_find=[]\n",
    "i=0\n",
    "for train_x,train_y in data_iter(batch_size,node,y_label):\n",
    "    pred_y=model(train_x)\n",
    "    l=loss(pred_y,train_y)\n",
    "    model.zero_grad()\n",
    "    l.backward()\n",
    "#     ww1=torch.Tensor(w1)\n",
    "    result.append((model.linear1.weight.grad.clone(),model.linear1.bias.grad.clone(),\n",
    "                   model.linear2.weight.grad.clone(),model.linear2.bias.grad.clone(),\n",
    "                   model.linear3.weight.grad.clone(),model.linear3.bias.grad.clone()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "##self implementation\n",
    "w1.requires_grad_(False)\n",
    "b1.requires_grad_(False)\n",
    "w2.requires_grad_(False)\n",
    "b2.requires_grad_(False)\n",
    "w3.requires_grad_(False)\n",
    "b3.requires_grad_(False)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1+np.exp(-z))\n",
    "#forward propagation:\n",
    "def forward_propagation(w1,b1,w2,b2,w3,b3,train_x):\n",
    "    z1=train_x@(w1.T)+b1\n",
    "#     print(z1)\n",
    "    y1=sigmoid(z1)\n",
    "#     print(y1)\n",
    "    z2=y1@(w2.T)+b2\n",
    "    y2=sigmoid(z2)\n",
    "#     print(z2)\n",
    "    z3=y2@(w3.T)+b3\n",
    "#     print(z3)\n",
    "    y3=z3\n",
    "    return z1,y1,z2,y2,y3\n",
    "\n",
    "def backward_propagation(y3,y2,z2,y1,z1,y_label,train_x,indicator):\n",
    "    if indicator==\"w1\":\n",
    "        return 2*sum(y3-y_label)*((w3*sigmoid(z2)*(1-sigmoid(z2)))@w2*sigmoid(z1)*(1-sigmoid(z1))).T@train_x\n",
    "    elif indicator=='b1':\n",
    "        return 2*sum(y3-y_label)*(w3*sigmoid(z2)*(1-sigmoid(z2)))@w2*sigmoid(z1)*(1-sigmoid(z1))\n",
    "    elif indicator=='w2':\n",
    "        return 2*sum(y3-y_label)*(w3*sigmoid(z2)*(1-sigmoid(z2))).T@y1\n",
    "    elif indicator=='b2':\n",
    "        return 2*sum(y3-y_label)*w3*sigmoid(z2)*(1-sigmoid(z2))\n",
    "    elif indicator=='w3':\n",
    "        return 2*sum(y3-y_label)*y2\n",
    "    elif indicator=='b3':\n",
    "        return 2*sum(y3-y_label)\n",
    "    else:\n",
    "        print(\"import indicator error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2=[]\n",
    "i=0\n",
    "for train_x,train_y in data_iter(batch_size,node,y_label):\n",
    "    z1,y1,z2,y2,y3=forward_propagation(w1,b1,w2,b2,w3,b3,train_x)\n",
    "    dl_dw3=backward_propagation(y3,y2,z2,y1,z1,train_y,train_x,\"w3\")\n",
    "    dl_db3=backward_propagation(y3,y2,z2,y1,z1,train_y,train_x,\"b3\")\n",
    "    dl_dw2=backward_propagation(y3,y2,z2,y1,z1,train_y,train_x,\"w2\")\n",
    "    dl_db2=backward_propagation(y3,y2,z2,y1,z1,train_y,train_x,\"b2\")\n",
    "    dl_dw1=backward_propagation(y3,y2,z2,y1,z1,train_y,train_x,\"w1\")\n",
    "    dl_db1=backward_propagation(y3,y2,z2,y1,z1,train_y,train_x,\"b1\")\n",
    "    result2.append((dl_dw1,dl_db1[0],dl_dw2,dl_db2[0],dl_dw3,dl_db3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(List_file,path):\n",
    "    if isinstance(List_file,list):\n",
    "        with open(path,\"w\") as f:\n",
    "            for i in range(len(List_file)):\n",
    "                f.write(str(i)+\":\"+\"\\n\"+\"W1_grad: \"+str(List_file[i][0])+\"\\n\"\n",
    "                        +\"b1_grad: \"+str(List_file[i][1])+\"\\n\"\n",
    "                        +\"W2_grad: \"+str(List_file[i][2])+\"\\n\"\n",
    "                        +\"b2_grad: \"+str(List_file[i][3])+'\\n'\n",
    "                        +\"W3_grad: \"+str(List_file[i][4])+\"\\n\"\n",
    "                        +\"b3_grad: \"+str(List_file[i][5])+'\\n'+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(result,\"./torch_autograd.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(result2,\"./my_autograd.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
